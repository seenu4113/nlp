{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmEt2v/Fvp1LstGr4mU8V9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seenu4113/nlp/blob/main/taSK_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6S8YGTFwa1d",
        "outputId": "34479d0d-48b0-479d-9964-8bf8af025065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns: ['Web', 'example', 'web', 'page', 'text', 'parts', 'speech', 'example', 'cat', 'dog', 'verb', 'prepositions']\n",
            "Verbs: ['contains', 'jumps', 'contains']\n",
            "Adjectives: ['various', 'lazy']\n",
            "Entities: []\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def pos_tag_and_extract_info(text):\n",
        "    doc = nlp(text)\n",
        "    nouns = []\n",
        "    verbs = []\n",
        "    adjectives = []\n",
        "    entities = []\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"NOUN\":\n",
        "            nouns.append(token.text)\n",
        "        elif token.pos_ == \"VERB\":\n",
        "            verbs.append(token.text)\n",
        "        elif token.pos_ == \"ADJ\":\n",
        "            adjectives.append(token.text)\n",
        "    for entity in doc.ents:\n",
        "        entities.append((entity.text, entity.label_))\n",
        "    return nouns, verbs, adjectives, entities\n",
        "web_document = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        "<title>Example Web Page</title>\n",
        "</head>\n",
        "<body>\n",
        "<p>This is an example web page. It contains some text with various parts of speech.</p>\n",
        "<p>For example, \"The cat jumps over the lazy dog\" contains a noun, a verb, and prepositions.</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "def extract_text_from_html(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    return soup.get_text()\n",
        "text_content = extract_text_from_html(web_document)\n",
        "nouns, verbs, adjectives, entities = pos_tag_and_extract_info(text_content)\n",
        "print(\"Nouns:\", nouns)\n",
        "print(\"Verbs:\", verbs)\n",
        "print(\"Adjectives:\", adjectives)\n",
        "print(\"Entities:\", entities)"
      ]
    }
  ]
}